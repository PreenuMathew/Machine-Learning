{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed2b4b52-0816-4c0f-af58-c60e4b9de968",
   "metadata": {},
   "source": [
    "Loading and Preprocessing (2 marks):\n",
    ">> Load the California Housing dataset using the fetch_california_housing function from sklearn.\n",
    ">> Convert the dataset into a pandas DataFrame for easier handling.\n",
    ">> Handle missing values (if any) and perform necessary feature scaling (e.g., standardization).\n",
    ">> Explain the preprocessing steps you performed and justify why they are necessary for this dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "543593a4-1817-4b63-ab98-30a4e1463bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# important libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.datasets import fetch_california_housing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4593d8fa-4b1c-4207-a870-c366eeed6f4d",
   "metadata": {},
   "source": [
    ">> Loading the data to df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ace8e06-c7e6-4465-af1e-c6ca2d4fec34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>4.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>3.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>3.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "\n",
       "   Longitude  Target  \n",
       "0    -122.23   4.526  \n",
       "1    -122.22   3.585  \n",
       "2    -122.24   3.521  \n",
       "3    -122.25   3.413  \n",
       "4    -122.25   3.422  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading the dataset\n",
    "data = fetch_california_housing()\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "df['Target'] = data.target\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78210bb2-5582-4d1c-bf4d-47c1fdc4d3bb",
   "metadata": {},
   "source": [
    ">> Handle missing values (if any) and perform necessary feature scaling (e.g., standardization).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b59a794f-21a5-4127-9494-89eab7958399",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MedInc        0\n",
       "HouseAge      0\n",
       "AveRooms      0\n",
       "AveBedrms     0\n",
       "Population    0\n",
       "AveOccup      0\n",
       "Latitude      0\n",
       "Longitude     0\n",
       "Target        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "685a1bab-eb3a-40d4-86e0-21d6b0fc0454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data after missing value handling and scaling:\n",
      "     MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
      "0  2.344766  0.982143  0.628559  -0.153758   -0.974429 -0.049597  1.052548   \n",
      "1  2.332238 -0.607019  0.327041  -0.263336    0.861439 -0.092512  1.043185   \n",
      "2  1.782699  1.856182  1.155620  -0.049016   -0.820777 -0.025843  1.038503   \n",
      "3  0.932968  1.856182  0.156966  -0.049833   -0.766028 -0.050329  1.038503   \n",
      "4 -0.012881  1.856182  0.344711  -0.032906   -0.759847 -0.085616  1.038503   \n",
      "\n",
      "   Longitude  Target  \n",
      "0  -1.327835   4.526  \n",
      "1  -1.322844   3.585  \n",
      "2  -1.332827   3.521  \n",
      "3  -1.337818   3.413  \n",
      "4  -1.337818   3.422  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "# Handle missing values\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "df_imputed = pd.DataFrame(imputer.fit_transform(df.drop('Target', axis=1)), columns=df.columns[:-1])\n",
    "df_imputed['Target'] = df['Target'] \n",
    "\n",
    "# Scaling (Standardization)\n",
    "scaler = StandardScaler()\n",
    "df_scaled = pd.DataFrame(scaler.fit_transform(df_imputed.drop('Target', axis=1)), columns=df_imputed.columns[:-1])\n",
    "df_scaled['Target'] = df_imputed['Target']\n",
    "\n",
    "# Output the processed data\n",
    "print(\"\\nData after missing value handling and scaling:\")\n",
    "print(df_scaled.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4d2ece-8d80-4105-911c-83961539c179",
   "metadata": {},
   "source": [
    "#Explain the preprocessing steps you performed and justify why they are necessary for this dataset.\n",
    "   Checking for Missing Values:>>\n",
    "   Before any other processing steps, it's crucial to check if there are any missing or NaN values in the dataset. Missing values can arise from various reasons such as incomplete data collection or errors during data entry. If we don't handle missing values, algorithms like linear regression ,decision trees may not work properly, as many machine learning models cannot handle missing values directly.\n",
    "   \n",
    "   Feature Scaling (Standardization)>>\n",
    "   Standardization transforms the features such that each feature has a mean of 0 and a standard deviation of 1.Many machine learning models, especially those that involve optimization , assume that the features have similar scales. Features with larger scales will dominate the learning process, which can lead to poor model performance or convergence issues. Standardization ensures that all features contribute equally to the model and that the model is not biased toward any one feature.\n",
    "   \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dfc04fe-286b-4d92-95b4-d694d81e6381",
   "metadata": {},
   "source": [
    "2.>>Regression Algorithm Implementation (5 marks):\n",
    " Implement the following regression algorithms:\n",
    "\n",
    "\n",
    "Linear Regression\n",
    "Decision Tree Regressor\n",
    "Random Forest Regressor\n",
    "Gradient Boosting Regressor\n",
    "Support Vector Regressor (SVR)\n",
    " For each algorithm:\n",
    "Provide a brief explanation of how it works.\n",
    "Explain why it might be suitable for this dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b407e5a0-9d52-4f5f-a476-f651ded04828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(columns=['Target']), df['Target'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7d788e92-e773-436b-bcfc-02ded1d0488b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models\n",
    "\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge Regression': Ridge(),\n",
    "    'Lasso Regression': Lasso(),\n",
    "    'Decision Tree': DecisionTreeRegressor(),\n",
    "    'Random Forest': RandomForestRegressor()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2ec442e8-e4cf-4675-be2c-35237b487539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluatig the models to find the best model\n",
    "\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    results[name] = {\n",
    "        'MAE': mean_absolute_error(y_test, y_pred),\n",
    "        'MSE': mean_squared_error(y_test, y_pred),\n",
    "        'RMSE': np.sqrt(mean_squared_error(y_test, y_pred)),\n",
    "        'R2 Score': r2_score(y_test, y_pred)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dc87e464-9826-414a-8421-dac5b86a2af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        MAE       MSE      RMSE  R2 Score\n",
      "Linear Regression  0.533200  0.555892  0.745581  0.575788\n",
      "Ridge Regression   0.533204  0.555803  0.745522  0.575855\n",
      "Lasso Regression   0.761578  0.938034  0.968521  0.284167\n",
      "Decision Tree      0.454557  0.507787  0.712592  0.612497\n",
      "Random Forest      0.326337  0.251897  0.501893  0.807772\n"
     ]
    }
   ],
   "source": [
    "# the results\n",
    "\n",
    "results_df = pd.DataFrame(results).T\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc6f59a-6969-4f1e-845b-edc1d55cd3ef",
   "metadata": {},
   "source": [
    "Linear Regression>> is a simple approach for problems where relationships are approximately linear.\n",
    "\n",
    "Decision Trees >>are flexible and non-linear but can overfit without proper tuning.\n",
    "\n",
    "Random Forest >>mitigates the overfitting problem by averaging predictions from multiple trees.\n",
    "\n",
    "Gradient Boosting>> builds an ensemble sequentially and can handle complex non-linear relationships.\n",
    "\n",
    "Support Vector Regression >>is good for non-linear problems but requires careful tuning of parameters and is computationally expensive."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bdf7e54-3859-4c1f-aa4f-9e06c7c6c444",
   "metadata": {},
   "source": [
    "3>> Model Evaluation and Comparison (2 marks):\n",
    "\n",
    "Evaluate the performance of each algorithm using the following metrics:\n",
    "Mean Squared Error (MSE)\n",
    "Mean Absolute Error (MAE)\n",
    "R-squared Score (RÂ²)\n",
    "Compare the results of all models and identify:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a48aa2-7ef1-42f4-96ec-8c1cfe3486c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning for the best model\n",
    "param_grid = {'n_estimators': [50, 100, 200], 'max_depth': [None, 10, 20]}\n",
    "grid_search = GridSearchCV(RandomForestRegressor(), param_grid, cv=5, scoring='r2')\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "713f6785-7b5d-4d9b-a710-8b2cd53e31ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'max_depth': None, 'n_estimators': 200}\n",
      "Best R2 Score: 0.8063924056740992\n"
     ]
    }
   ],
   "source": [
    "# the best parameters and model score\n",
    "\n",
    "y_pred_best = grid_search.best_estimator_.predict(X_test)\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best R2 Score:\", r2_score(y_test, y_pred_best))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be03828-6906-4aa9-84b3-07277987c2f3",
   "metadata": {},
   "source": [
    "The best-performing algorithm with justification.\n",
    "The worst-performing algorithm with reasoning.\n",
    "\n",
    "Random Forest is the best-performing model because it handles complex relationships between features and target variables well and reduces overfitting through its ensemble approach.\n",
    "\n",
    "Linear Regression is the worst-performing model in this case due to its inherent assumption of linearity, which is not a good fit for this dataset, resulting in poor prediction accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e051fad-b3a8-4dac-86eb-36c8a585338c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
